[{"content":"SVM学习 实践 实践方式1：使用sklearn工具包内置SVM模型实现 简单二分类（鸢尾花的类别分类） 总体代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 # 导入必要的库 import numpy as np import matplotlib.pyplot as plt from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.svm import SVC from sklearn.metrics import accuracy_score, classification_report plt.rcParams[\u0026#39;font.sans-serif\u0026#39;] = [\u0026#39;SimHei\u0026#39;] # 用来正常显示中文标签 plt.rcParams[\u0026#39;axes.unicode_minus\u0026#39;] = False # 用来正常显示负号 # 1. 加载数据 iris = load_iris() # 只选择前两个特征（萼片长度和宽度）和前两个类别 X = iris.data[iris.target != 2, :2] # 只取前两个特征 y = iris.target[iris.target != 2] # 只取前两个类别 # 2. 数据预处理 - 标准化 scaler = StandardScaler() X_scaled = scaler.fit_transform(X) # 3. 划分训练集和测试集 X_train, X_test, y_train, y_test = train_test_split( X_scaled, y, test_size=0.2, random_state=42) # 4. 创建和训练SVM模型 svm_classifier = SVC(kernel=\u0026#39;linear\u0026#39;, random_state=42) svm_classifier.fit(X_train, y_train) # 5. 预测 y_pred = svm_classifier.predict(X_test) # 6. 评估模型 print(\u0026#34;准确率：\u0026#34;, accuracy_score(y_test, y_pred)) print(\u0026#34;\\n分类报告：\\n\u0026#34;, classification_report(y_test, y_pred)) # 7. 可视化决策边界 def plot_decision_boundary(X, y, model, title=\u0026#34;SVM决策边界\u0026#34;): # 创建网格点 x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1 y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02)) # 预测网格点的类别 Z = model.predict(np.c_[xx.ravel(), yy.ravel()]) Z = Z.reshape(xx.shape) # 绘制决策边界 plt.figure(figsize=(10, 8)) plt.contourf(xx, yy, Z, alpha=0.4) plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.8) plt.xlabel(\u0026#39;萼片长度 (标准化后)\u0026#39;) plt.ylabel(\u0026#39;萼片宽度 (标准化后)\u0026#39;) plt.title(title) # 绘制支持向量 plt.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=100, linewidth=1, facecolors=\u0026#39;none\u0026#39;, edgecolors=\u0026#39;k\u0026#39;, label=\u0026#39;支持向量\u0026#39;) plt.legend() plt.show() # 绘制决策边界 plot_decision_boundary(X_scaled, y, svm_classifier) 代码拆分解释 1 2 3 4 5 6 7 8 # 导入必要的库 import numpy as np import matplotlib.pyplot as plt from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.svm import SVC from sklearn.metrics import accuracy_score, classification_report import numpy as np ：用于科学计算的基础库，提供多维数组对象支持，提供大量的数学函数和数组操作方法\n代码中主要用于：\n数组操作（如 np.meshgrid） 数值计算 数组的切片和索引 import matplotlib.pyplot as plt：Python的主要绘图库，用于创建静态、动态或交互式的可视化图表\n代码中主要用于：\n绘制决策边界（plt.contourf） 绘制散点图（plt.scatter） 设置图表标题、标签等（plt.title, plt.xlabel) Scikit-learn的相关模块\nfrom sklearn.datasets import load_iris：加载内置数据集\nfrom sklearn.model_selection import train_test_split：数据集分割\nfrom sklearn.preprocessing import StandardScaler：数据标准化\nfrom sklearn.svm import SVC：支持向量机分类器\nfrom sklearn.metrics import accuracy_score, classification_report：模型评估工具\n具体作用：\nload_iris：\n加载鸢尾花数据集 包含150个样本，4个特征，3个类别 train_test_split：\n将数据集随机分割为训练集和测试集 可以设置分割比例和随机种子 StandardScaler：\n数据标准化工具 将特征转换为标准正态分布（均值为0，方差为1） 对SVM算法很重要，因为SVM对特征尺度敏感 SVC (Support Vector Classification)：\n支持向量机分类器的实现 支持多种核函数（linear, rbf, poly等） 包含多个可调参数（C, kernel, gamma等） accuracy_score：\n计算分类准确率 返回正确预测的样本比例 classification_report：\n生成详细的分类报告 包含精确率(precision)、召回率(recall)、F1分数等指标 对每个类别分别计算这些指标 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 1. 加载数据 iris = load_iris() # 只选择前两个特征（萼片长度和宽度）和前两个类别 X = iris.data[iris.target != 2, :2] # 只取前两个特征 y = iris.target[iris.target != 2] # 只取前两个类别 # 2. 数据预处理 - 标准化 scaler = StandardScaler() X_scaled = scaler.fit_transform(X) # 3. 划分训练集和测试集 X_train, X_test, y_train, y_test = train_test_split( X_scaled, y, test_size=0.2, random_state=42) # 4. 创建和训练SVM模型 svm_classifier = SVC(kernel=\u0026#39;linear\u0026#39;, random_state=42) svm_classifier.fit(X_train, y_train) # 5. 预测 y_pred = svm_classifier.predict(X_test) # 6. 评估模型 print(\u0026#34;准确率：\u0026#34;, accuracy_score(y_test, y_pred)) print(\u0026#34;\\n分类报告：\\n\u0026#34;, classification_report(y_test, y_pred)) 使用sklearn工具进行机器学习的基本流程：\n加载数据→数据预处理→划分训练集与测试机→创建模型→训练模型→进行预测→模型评估\n具体的使用不做过多阐述，查询sklearn的使用方法可知\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 7. 可视化决策边界 def plot_decision_boundary(X, y, model, title=\u0026#34;SVM决策边界\u0026#34;): # 创建网格点 x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1 y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02)) # 预测网格点的类别 Z = model.predict(np.c_[xx.ravel(), yy.ravel()]) Z = Z.reshape(xx.shape) # 绘制决策边界 plt.figure(figsize=(10, 8)) plt.contourf(xx, yy, Z, alpha=0.4) plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.8) plt.xlabel(\u0026#39;萼片长度 (标准化后)\u0026#39;) plt.ylabel(\u0026#39;萼片宽度 (标准化后)\u0026#39;) plt.title(title) # 绘制支持向量 plt.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=100, linewidth=1, facecolors=\u0026#39;none\u0026#39;, edgecolors=\u0026#39;k\u0026#39;, label=\u0026#39;支持向量\u0026#39;) plt.legend() plt.show() # 绘制决策边界 plot_decision_boundary(X_scaled, y, svm_classifier) 定义一个绘制图像的函数，用于可视化\n运行结果与分析 可视化图的解释： 颜色区域：\n紫色区域：分类为类别0的区域 黄色区域：分类为类别1的区域 中间的线：决策边界 散点：\n紫色点：类别0的样本 黄色点：类别1的样本 带黑色圆圈的点：支持向量（最接近决策边界的点） 终端打印结果： 1 2 3 4 5 6 7 8 9 10 准确率： 1.0 分类报告： precision recall f1-score support 0 1.00 1.00 1.00 12 1 1.00 1.00 1.00 8 accuracy 1.00 20 macro avg 1.00 1.00 1.00 20 weighted avg 1.00 1.00 1.00 20 准确率1.0：表示模型的预测准确率为100%\n各指标含义：\n（1）Precision（精确率）：\n在被预测为正类的样本中，真实为正类的比例 1.00表示没有误判 （2）Recall（召回率）：\n在真实为正类的样本中，被正确预测出来的比例 1.00表示所有正类都被找出 （3）F1-score：\nPrecision和Recall的调和平均数 1.00表示完美的分类效果 （4）Support：\n每个类别的测试样本数 类别0有12个样本 类别1有8个样本 与支持向量机的关系： （1）决策边界：\nSVM寻找最优的超平面（在2D中表现为一条线）来分隔不同类别 图中的分界线就是SVM找到的最优分隔线 （2）支持向量：\n图中带黑色圆圈的点是支持向量 这些点最接近决策边界 它们\u0026quot;支撑\u0026quot;着最大间隔 （3）最大间隔：\nSVM试图使决策边界与最近的数据点（支持向量）之间的距离最大 这种最大间隔特性有助于提高模型的泛化能力 结果分析： 准确率100%说明这是一个线性可分的问题\n支持向量（带圆圈的点）清晰地定义了决策边界\n两个类别被很好地分开，没有重叠区域\n","date":"2024-12-07T15:00:00+08:00","permalink":"https://0Hzc.github.io/p/python%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","title":"python学习记录_机器学习"},{"content":"本文记录学习yolov11网络结构\n1.需要掌握什么内容？\n2.需要掌握到什么程度？\n3.自检掌握程度\nGithub开源仓库中yolov11相关内容 代码结构分析 在ultralytics仓库中，网络结构相关的核心目录：\n1 2 3 4 5 6 7 ultralytics/ ├── models/ # 模型定义 ├── nn/ # 网络组件 │ ├── modules/ # 基础模块 │ └── tasks/ # 不同任务的实现 └── cfg/ # 配置文件 └── models/ # 模型配置 网络架构组成 从配置文件 ultralytics/cfg/models/11/yolo11.yaml\n可以看到，整个网络分为三个主要部分：\n1.Backbone (主干网络)\n2.Neck (颈部网络)\n3.Head (检测头)\n需要掌握的内容 1.了解特征提取的层次性\n2.理解下采样的作用\n3.知道感受野的概念\n4.理解多尺度特征融合的重要性\n5.了解特征金字塔网络(FPN)的原理\n6.知道为什么需要特征增强\n7.理解预测头的输出格式\n8.了解分类和回归的区别\n9.知道如何解析预测结果\n掌握程度 1.能说出三个组件的基本功能\n2.理解特征提取的概念\n3.知道基本的网络结构\n4.能解释各组件之间的联系\n5.理解特征融合的必要性\n6.能分析网络的创新点\n7.能修改网络结构\n8.能针对具体任务优化网络\n9.理解性能和效率的平衡\n自测问题 问题1：为什么主干网络要逐步降低特征图尺寸？\n问题2：颈部网络为什么需要双向特征融合？\n问题3：检测头如何处理不同尺度的预测？\n尝试修改backbone结构，观察效果\n观察不同层的特征图输出\n练习2：分析网络在不同场景的表现\n理解预测结果的差异\n如何优化网络结构以提高特定目标的检测效果？\n在资源受限情况下如何平衡性能和效率？\n不同组件对最终性能的影响程度如何？\n","date":"2024-11-30T15:00:00+08:00","permalink":"https://0Hzc.github.io/p/yolo%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%950/","title":"yolo学习记录0"},{"content":"学习yolov11的一些基本概念，和一些基础操作内容的作用\n配置文件 在yolov11下载的工具包中，\u0026ldquo;ultralytics-main\\ultralytics\\cfg\\models\\11\\yolo11.yaml\u0026rdquo;\n该文件中包括了yolov11的配置文件\n相关概念 空间注意力\n为什么要计算空间注意力 帮助模型聚焦于重要区域 抑制无关背景的干扰 增强特征的表达能力 提高检测精度\n如何计算空间注意力 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class SpatialAttention(nn.Module): def __init__(self, kernel_size=7): super().__init__() padding = 3 if kernel_size == 7 else 1 self.cv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False) self.act = nn.Sigmoid() def forward(self, x): # 1. 计算通道维度的平均值和最大值 avg_out = torch.mean(x, 1, keepdim=True) # 平均池化 max_out, _ = torch.max(x, 1, keepdim=True) # 最大池化 # 2. 拼接这两个特征图 x_cat = torch.cat([avg_out, max_out], 1) # 3. 通过卷积层和sigmoid得到注意力权重 attention = self.act(self.cv1(x_cat)) # 4. 将注意力权重与原始特征相乘 return x * attention 计算步骤：\n1.特征统计：\n计算特征图的通道平均值 计算特征图的通道最大值\n2.特征融合：\n将平均值和最大值特征图拼接 得到表达空间信息的特征图\n3.注意力权重：\n用7×7卷积处理融合特征 通过sigmoid得到0-1之间的权重\n4.特征增强：\n将注意力权重与原始特征相乘 突出重要区域，抑制次要区域\n作用 让网络能够：\n自适应地关注重要空间位置 减少背景噪声的影响 提高特征的判别能力 自注意力\n为什么要计算自注意力 1.1捕获长距离依赖关系\n举个例子：\n检测人脸时，需要同时看到眼睛、鼻子、嘴巴等特征 传统卷积只能看到局部区域 自注意力可以直接建立任意两个位置的关联\n1.2自适应特征提取\n比如检测一只猫：\n传统卷积：固定的感受野大小\n自注意力：\n可以关注猫的整体轮廓 也可以关注细节特征(如耳朵、胡须) 注意力权重会自动调整\n1.3上下文理解能力\n每个位置都能获取全局信息 特征之间可以互相交互 增强了对场景的理解\n1.4动态权重分配\n自动学习重要特征的权重 抑制无关背景的干扰 提高特征的判别能力\n1.5并行计算效率\n可以并行计算多个头 每个头关注不同的特征模式 提高了特征提取的多样性 Shortcut 连接\nshortcut 连接是一种网络设计技巧，主要有以下特点：\n基本原理 在网络中创建一条捷径 让信息可以跳过某些层直接传递 类似于高速公路的快车道\n作用\n2.1 解决梯度消失问题\n深层网络训练困难 shortcut 提供梯度反向传播的快速通道 帮助深层网络也能有效训练\n2.2 保留原始信息\n让网络可以直接访问浅层特征 避免信息在传递过程中损失 提高特征利用效率\n提升模型性能 加快收敛速度 提高特征提取能力 改善最终检测效果 主干网络 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # YOLO11n backbone backbone: # [from, repeats, module, args] - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2 - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4 - [-1, 2, C3k2, [256, False, 0.25]] - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8 - [-1, 2, C3k2, [512, False, 0.25]] - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16 - [-1, 2, C3k2, [512, True]] - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32 - [-1, 2, C3k2, [1024, True]] - [-1, 1, SPPF, [1024, 5]] # 9 - [-1, 2, C2PSA, [1024]] # 10 [-1, 2, C3k2, [256, False, 0.25]] 这四个参数的含义：\n-1：表示输入来源 -1 表示使用上一层的输出作为输入 如果是其他数字(如6)，则表示使用第6层的输出作为输入 这种设计允许网络创建跳跃连接 2：表示重复次数 这个模块会重复执行2次 每次执行都会使用前一次的输出作为输入 增加网络深度和特征提取能力 C3k2：模块名称 表示使用C3k2模块（一种改进的CSP模块） [256, False, 0.25]：模块参数 可见主干网络包括以下关键组件： 1.初始卷积层 2.特征提取层\n1.初始卷积层 1 2 - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2 - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4 第一层卷积：Conv, [64, 3, 2]\n输入：原始图像 (3通道)\n输出：64通道特征图\n卷积核：3×3\n步长：2\n第二层卷积：Conv, [128, 3, 2]\n输入：64通道特征图\n输出：128通道特征图\n卷积核：3×3\n步长：2\n步长2实现降采样\n通道数增加扩展特征维度\n通道数增加的意义 每个通道代表一种特征模式 更多通道 = 可以学习更多种类的特征 类比：用64/128支画笔来画画，画笔越多，可以表达的细节越丰富 主要作用\n1.降采样\n每层步长为2，两层共降采样4倍 640×640 → 320×320 → 160×160 减少后续计算量\n2.特征提取\n提取基础的视觉特征（如边缘、纹理等） 通道数增加：3 → 64 → 128 增加特征表达能力\n3.信息压缩\n压缩空间维度 扩展通道维度 为后续深层特征提取做准备 2.特征提取层 1 2 3 4 5 6 7 8 9 - [-1, 2, C3k2, [256, False, 0.25]] - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8 - [-1, 2, C3k2, [512, False, 0.25]] - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16 - [-1, 2, C3k2, [512, True]] - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32 - [-1, 2, C3k2, [1024, True]] - [-1, 1, SPPF, [1024, 5]] # 9 - [-1, 2, C2PSA, [1024]] # 10 包含三个模块\nC3k2 模块 1.参数说明：\n[256, False, 0.25]： 256：输出通道数 False：是否使用 shortcut 连接 0.25：通道压缩比例\n2.工作原理：\n将输入特征分成两部分 一部分直接通过 另一部分经过多个卷积层处理 最后合并两部分特征\n3.优势：\n减少计算量 保持梯度流动 增强特征提取能力\nSPPF 模块 1.参数说明：\n[1024, 5]： 1024：输出通道数 5：最大池化核大小\n2.工作原理：\n输入特征先经过 1×1 卷积降维 连续进行最大池化，得到不同尺度特征 将所有特征拼接 最后用 1×1 卷积整合\n3.优势：\n获取多尺度上下文信息 比传统 SPP 更快 增大感受野 模块作用： 1.渐进式感受野扩大：\n第一次池化：小感受野，捕获局部特征 第二次池化：中等感受野，捕获中等范围特征 第三次池化：大感受野，捕获全局特征\n2.计算效率更高：\nSPP：需要3个独立的池化分支 SPPF：串行池化，复用计算结果\n3.特征融合更完整：\n将不同感受野的特征concat 通过1×1卷积整合多尺度信息\nC2PSA 模块 1.参数说明：\n[1024]：输出通道数\n2.工作原理：\n2.1 空间注意力计算：\n生成空间注意力图 突出重要区域 抑制无关区域\n2.2 特征增强\n原始特征与注意力图相乘 增强重要特征 抑制噪声特征\n3.优势：\n自适应特征增强 提高特征表达能力 改善检测性能 模块作用 1.特征分离与处理：\n输入特征通过cv1分成两部分(a,b) a分支保持原始信息 b分支经过PSA注意力处理 最后将两部分特征重新融合\n2.注意力增强：\n使用PSABlock进行注意力计算 每个PSABlock包含self-attention机制 通过多头注意力处理空间信息\n","date":"2024-11-29T15:00:00+08:00","permalink":"https://0Hzc.github.io/p/yolo%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%951/","title":"yolo学习记录1"},{"content":"记录给云服务器设置本地局域网代理\n大致概括 通过ssh建立本地代理服务器与云服务器的连接，开启本地代理，关闭本地代理服务器防火墙，关闭云服务器防火墙，设置云服务器代理\n1.建立ssh连接 将本地代理端口映射至云服务器的ssh连接端口，如22，10022\n1 2 3 #打开代理终端，进行ssh配置连接 #以本地代理端口为7897为例 ssh -i C:\\Users\\H\\.ssh\\id_rsa -R 7897:localhost:7897 username@ip -p 10022 确保ssh服务器连接成功 注解：其中-i 后面设置的参数是密钥对的地址，@前面是云服务器的用户名，@后面是云服务器的公网ip，-p 后面设置的是云服务器的ssh连接端口\n2.开启本地代理 启动clash或其他代理工具，开启局域网连接，选择转发端口为7897\n3.关闭本地代理服务器防火墙 4.设置云服务器的代理 1 2 3 4 5 6 7 8 9 10 #设置http代理 export http_proxy=http://localhost:7897 #设置https代理 export https_proxy=http://localhost:7897 #查看云服务代理 env | grep -i proxy #测试代理是否成功 curl -i www.google.com 5.取消代理 1 2 export http_proxy=\u0026#34;\u0026#34; export https_proxy=\u0026#34;\u0026#34; ","date":"2024-11-22T15:00:00+08:00","permalink":"https://0Hzc.github.io/p/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/","title":"云服务器代理设置"},{"content":"记录并总结python中与终端的交互处理、参数传递等\n实现两种终端处理方式，一种为命令行参数，一种为终端输入 终端输入 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #导入模块 import sys from colorama import Fore, Style ## 定义终端获取输入函数 def get_user_input(): print(f\u0026#34;{Fore.CYAN}请输入以下参数：{Style.RESET_ALL}\u0026#34;) # 获取输入数据路径 while True: input_path = input(f\u0026#34;{Fore.YELLOW}请输入.SAFE结尾的文件夹绝对路径：{Style.RESET_ALL}\u0026#34;).strip() if os.path.exists(input_path) and input_path.endswith(\u0026#39;.SAFE\u0026#39;): print(f\u0026#34;{Fore.GREEN}成功输入输入数据路径：{input_path}{Style.RESET_ALL}\u0026#34;) break else: print(f\u0026#34;{Fore.RED}错误：路径不存在或不是有效的.SAFE文件夹，请重新输入{Style.RESET_ALL}\u0026#34;) return input_path ## 调用函数 input_path = get_user_input() print(f\u0026#34;{Fore.MAGENTA}输入路径为：{input_path}{Style.RESET_ALL}\u0026#34;) 注：\n命令行参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #导入模块 import argparse ## 定义参数设置函数 def parse_arguments(): # 设置参数解析器 parser = argparse.ArgumentParser(description=\u0026#39;护花米草遥感识别处理程序\u0026#39;) ## 添加必填参数与非必填参数 #必需的参数 parser.add_argument(\u0026#39;-i\u0026#39;, \u0026#39;--input\u0026#39;, required=True, help=\u0026#39;输入数据文件夹路径（包含nc文件）\u0026#39;) parser.add_argument(\u0026#39;-w\u0026#39;, \u0026#39;--word\u0026#39;, required=True, help=\u0026#39;Word模板文件路径（.docx文件）\u0026#39;) parser.add_argument(\u0026#39;-o\u0026#39;, \u0026#39;--output\u0026#39;, required=True, help=\u0026#39;输出结果保存路径\u0026#39;) #非必填，带默认值的参数 parser.add_argument(\u0026#39;--threshold\u0026#39;, type=float, default=0.5, help=\u0026#39;阈值\u0026#39;) # 解析参数 args = parser.parse_args() #返回参数 return args ## 调用函数 def main(): args = parse_arguments() print(f\u0026#34;{Fore.MAGENTA}输入路径为：{args.input_path}{Style.RESET_ALL}\u0026#34;) 注：\n","date":"2024-11-21T15:00:00+08:00","permalink":"https://0Hzc.github.io/p/python%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%951/","title":"python学习记录1"},{"content":"本文记录如何使用yjs+quill协同编辑器进行二次部署,使用已经搭建过的yjsdemo实现快速部署 用于服务器更新资源，需要二次部署时使用\n步骤1： 从github仓库中下载源码\n步骤2： 安装npm、nginx反向代理\n步骤3： 在工程目录下npm install\n步骤4： 编辑nginx配置文件,以petherfish.cn为例\n1 sudo nano /etc/nginx/sites-available/petherfish.cn 配置文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 server { listen 80; listen [::]:80; server_name petherfish.cn; # 编辑器的反向代理配置 location /edit { proxy_pass http://localhost:5173; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # WebSocket 支持 proxy_read_timeout 86400; } # WebSocket 服务器的反向代理配置 location /ws { proxy_pass http://localhost:1234; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; proxy_set_header Host $host; proxy_read_timeout 86400; } # 用于处理其他请求 location / { root /usr/share/nginx/html; index index.html index.htm; try_files $uri $uri/ =404; } # 日志配置 access_log /var/log/nginx/petherfish.cn.access.log; error_log /var/log/nginx/petherfish.cn.error.log; } 重启nginx\n1 sudo systemctl restart nginx 步骤5： 本地测试\n1 npm start 1 npm run dev 无报错后访问petherfish.cn/edit/,测试是否可以正常访问\n步骤6： 编写vite.config.js文件，系统服务文件 编写webserver.py文件，系统服务文件\n","date":"2024-11-20T15:00:00+08:00","permalink":"https://0Hzc.github.io/p/%E5%A6%82%E4%BD%95%E5%86%8D%E6%AC%A1%E9%83%A8%E7%BD%B2yjs-quill%E5%8D%8F%E5%90%8C%E7%BC%96%E8%BE%91%E5%99%A8/","title":"如何再次部署yjs+quill协同编辑器"},{"content":"学习开发python项目 附录内容为python的相关语法和库的介绍 主体内容为python项目开发流程和框架结构\nstep1 创建项目目录 在项目目录下创建以下文件：\nREADME.md modules/init.py、modules/readers/init.py utils/init.py main.py step2 编写代码 编写 init.py文件 从模块中的readers的__init__.py文件为例，开始编写代码\n1 2 3 4 5 6 7 #定义一个文件类型的枚举，用于标识不同的文件类型 from enum import Enum class FileType(Enum): H5 = \u0026#34;h5\u0026#34; NC = \u0026#34;nc\u0026#34; RULE = \u0026#34;rule\u0026#34; 编写公共模块 编写基础功能模块 附录 文件说明 关于 utils 文件夹 utils 是 \u0026ldquo;utilities\u0026rdquo;（实用工具）的缩写 这个文件夹用来存放一些通用的工具函数或类 比如文件处理、日志记录、时间格式转换等公共功能 这些功能会被多个其他模块重复使用，所以单独放在一起便于维护\n关于 readers 文件夹 这是运用了模块化编程的思想 readers 文件夹专门用来存放所有与文件读取相关的代码 这样的组织方式有几个好处： 代码结构清晰 相关功能集中管理 便于维护和扩展\n关于 init.py 文件 在 Python 中，任何包含 init.py 文件的文件夹都会被视为一个 Python 包 这个文件可以是空的，仅用来标识这个文件夹是一个 Python 包 它允许你使用 import 语句导入这个文件夹中的模块 例如：\n1 2 # 如果没有 __init__.py，这样的导入是不可能的 from modules.readers import xxx 思想流程 检验系统其中包括：文件转换 → 而文件转换包括其中：文件读取→ 而文件读取时，如果有新的文件类型需要读取，那么就可以制作一个文件读取器 ，后续需要新建新的文件读取，只需要维护这个文件读取器即可 → 文件读取器要能够自动实现类型添加 → 可以在readers文件夹中的 init.py文件中定义一个枚举类，在readers文件夹中创建一个reader_factory.py文件,在这个文件中定义一个readerfactory的类，在reader_factory中创建创建读取器对象的静态方法,之后只要添加新的类型处理，只需要在__init__.py文件中添加新的类型，在reader_factory.py文件中添加新的类型匹配处理即可\n思想流程图：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 检验系统 └── 文件转换 └── 文件读取 ├── readers/__init__.py (定义文件类型枚举) │ └── class FileType(Enum): │ H5 = \u0026#34;h5\u0026#34; │ NC = \u0026#34;nc\u0026#34; │ RULE = \u0026#34;rule\u0026#34; │ # 未来可以在这里添加新类型 │ NEW_TYPE = \u0026#34;new\u0026#34; ← 步骤1：添加新类型 │ ├── readers/reader_factory.py │ └── class ReaderFactory: │ └── create_reader(): │ readers = { │ FileType.H5: H5Reader, │ FileType.NC: NCReader, │ FileType.RULE: RuleReader, │ FileType.NEW_TYPE: NewReader ← 步骤2：添加对应的处理器 │ } │ └── readers/new_reader.py ← 步骤3：实现新的读取器 └── class NewReader(BaseReader): └── def _read(self): # 实现具体的读取逻辑 os库 介绍 os (Operating System) 库是 Python 的标准库之一，提供了与操作系统交互的各种功能，让我们可以使用 Python 来执行操作系统级别的操作，比如：文件和目录操作、进程管理、环境变量操作、路径操作等\n常用方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ##路径操作 (os.path) # 检查文件或目录是否存在 os.path.exists(\u0026#34;file.txt\u0026#34;) # 返回 True 或 False # 获取文件名和扩展名 os.path.splitext(\u0026#34;file.txt\u0026#34;) # 返回 (\u0026#39;file\u0026#39;, \u0026#39;.txt\u0026#39;) # 拼接路径 os.path.join(\u0026#34;dir\u0026#34;, \u0026#34;file.txt\u0026#34;) # 返回 \u0026#34;dir/file.txt\u0026#34; (Linux) 或 \u0026#34;dir\\file.txt\u0026#34; (Windows) # 获取绝对路径 os.path.abspath(\u0026#34;file.txt\u0026#34;) # 判断是否为目录 os.path.isdir(\u0026#34;dirname\u0026#34;) # 判断是否为文件 os.path.isfile(\u0026#34;file.txt\u0026#34;) ##目录操作 # 获取当前工作目录 os.getcwd() # 改变当前工作目录 os.chdir(\u0026#34;path/to/dir\u0026#34;) # 列出目录内容 os.listdir(\u0026#34;dirname\u0026#34;) # 创建目录 os.mkdir(\u0026#34;dirname\u0026#34;) # 创建单个目录 os.makedirs(\u0026#34;a/b/c\u0026#34;) # 创建多级目录 ##文件操作 # 重命名文件或目录 os.rename(\u0026#34;old.txt\u0026#34;, \u0026#34;new.txt\u0026#34;) # 删除文件 os.remove(\u0026#34;file.txt\u0026#34;) # 删除空目录 os.rmdir(\u0026#34;dirname\u0026#34;) ##系统相关 # 获取环境变量 os.getenv(\u0026#34;PATH\u0026#34;) # 获取系统名称 os.name # \u0026#39;nt\u0026#39; (Windows) 或 \u0026#39;posix\u0026#39; (Linux/Unix) @staticmethod 装饰器 @staticmethod 装饰器用于定义一个静态方法，静态方法不需要访问类的实例属性，也不需要访问类的实例方法，它只是一些与类相关的工具函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Calculator: # 1. 普通实例方法（需要实例化才能调用） def add(self, a, b): return a + b # 2. 静态方法（不需要实例化就能调用） @staticmethod def subtract(a, b): return a - b # 使用实例方法 calc = Calculator() result1 = calc.add(1, 2) # 需要先创建实例 # 使用静态方法 result2 = Calculator.subtract(5, 3) # 直接通过类名调用 all 变量 all 变量用于定义模块的公共接口，它是一个列表，列出了模块中所有可以被外部导入的变量、函数或类\n1 __all__ = [\u0026#39;check_file_exists\u0026#39;, \u0026#39;get_file_extension\u0026#39;] ","date":"2024-11-09T15:00:00+08:00","permalink":"https://0Hzc.github.io/p/%E5%AD%A6%E4%B9%A0python%E9%A1%B9%E7%9B%AE/","title":"学习python项目"},{"content":"本文主要记录如何配置yolov11所需的anaconda环境以及下载并运行初始模型， 其中关于如何下载anaconda，配置conda至系统环境变量以及如何使用pycharm IDE进行选择conda环境见本文末尾的参考链接\n如何配置环境，并下载初始模型进行测试 conda基础命令 1 2 3 4 5 6 7 8 #查看当前存在哪些conda虚拟环境 conda env list #新建conda虚拟环境 conda create -n yolov11 python=3.10 #yolov11可随意更改,意义为创建的虚拟环境的名字 #激活conda虚拟环境/选择某个环境作为编译环境 conda activate yolov11 #此处的yolov11则为新建时创建的虚拟环境名字 步骤1：GPU安装相关驱动 参考文章尾部链接安装cuda、cudnn\n步骤2：配置虚拟环境 1 2 3 4 5 6 7 8 #查看当前环境存在哪些包 pip list #安装pytorch框架 pip install torch==2.0.0+cu118 torchvision==0.15.1+cu118 --extra-index-url https://download.pytorch.org/whl/cu118 #安装yolo命令包 pip install ultralytics 步骤3：下载模型、预训练权重 访问地址：https://github.com/ultralytics/ultralytics/（yolo的github仓库） 下载使用COCO数据集训练的得到的预训练权重文件、在仓库的Readme的model下的Detection (COCO)部分\nModel YOLO11n YOLO11s YOLO11m YOLO11l YOLO11x 在仓库的realse处下载模型压缩包\n步骤4：使用模型进行测试 1.将在realse下载的模型压缩包解压，并在IDE中打开，让终端在该目录下即可 2.将下载的预训练权重放置该目录下 3.随意准备一张测试图放置该目录下，准备用作目标检测\n1 yolo predict model=yolo11n.pt source=\u0026#39;cat.jpg\u0026#39; #yolo11n.pt修改为下载的预训练权重，cat.jpg修改为准备的图片名和格式 参考链接 https://blog.csdn.net/qq_67105081/article/details/143270109?spm=1001.2014.3001.5502\n","date":"2024-11-08T15:00:00+08:00","permalink":"https://0Hzc.github.io/p/%E5%88%9D%E6%AC%A1%E4%BD%BF%E7%94%A8yolov11%E8%BF%9B%E8%A1%8C%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/","title":"初次使用yolov11进行目标检测"},{"content":"本文记录如何使用github的两个仓库进行部署hugo生成的静态html博客\n流程 步骤1： 在github上建立一个私有库，用于存放hugo的源代码（后续记录如何本地安装并调试hugo进行网页效果展示）\n步骤2： 再建立另一个仓库：0hzc.github.io，此仓库命名必须命名为xxx.github.io，xxx为你的github用户名\n步骤3： 在本地调试完hugo的网页确定无误后，在目录下新建.github文件夹，此文件夹与hugo new site 的文件夹同级,再在.github文件夹下新建一个名为workflows的文件夹\n步骤4： 在.github/workflows文件夹下新建xxx.yml文件，xxx随意命名，此文件为githubwebpages的自动部署文件，内容可填写为如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 name: github pages # 名字自取 on: push: branches: - main # 这里的意思是当 main分支发生push的时候，运行下面的jobs，这里先改为github-actions jobs: deploy: # 任务名自取 runs-on: ubuntu-latest\t# 在什么环境运行任务 steps: - uses: actions/checkout@v2\t# 引用actions/checkout这个action，与所在的github仓库同名 with: submodules: true # Fetch Hugo themes (true OR recursive) 获取submodule主题 fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo\t# 步骤名自取 uses: peaceiris/actions-hugo@v2\t# hugo官方提供的action，用于在任务环境中获取hugo with: hugo-version: \u0026#39;latest\u0026#39;\t# 获取最新版本的hugo extended: true - name: Build run: hugo --minify\t# 使用hugo构建静态网页 - name: Deploy uses: peaceiris/actions-gh-pages@v3\t# 一个自动发布github pages的action with: # github_token: ${{ secrets.GITHUB_TOKEN }} 该项适用于发布到源码相同repo的情况，不能用于发布到其他repo external_repository: 0Hzc/0Hzc.github.io\t# 发布到哪个repo personal_token: ${{ secrets.hzcblog }}\t# 发布到其他repo需要提供上面生成的personal access token publish_dir: ./public\t# 注意这里指的是要发布哪个文件夹的内容，而不是指发布到目的仓库的什么位置，因为hugo默认生成静态网页到public文件夹，所以这里发布public文件夹里的内容 publish_branch: main\t# 发布到哪个branch 其中需要做修改的为“ external_repository: 0Hzc/0Hzc.github.io”需要将对应的部分改为步骤2的仓库名，“personal_token: ${{ secrets.hzcblog }}”需要将对应的部分改为生成的personal access token\n步骤5： 使用git工具推送至步骤一建立的仓库即可\ngit的相关使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #将本地文件进行git git init #连接远程仓库 git remote add origin xxxxx #origin是远程仓库的别名，可以自定义，后续推送至仓库时需要用到这个别名，xxxx是远程仓库的url #检查连接的远程仓库，以及在本地的别名 git remote -v #将文件/修改的文件，添加至暂存区 git add . #也可以指定文件添加 将.改为具体文件路径 #可查看暂存区有哪些文件 git status #确定暂存区无误，确定提交 git commit -m \u0026#34;提交信息\u0026#34; #提交信息为自定义，可以写本次提交的说明 #将暂存区的文件提交至远程仓库 git push origin main #origin是远程仓库的别名，main是远程仓库的分支（branch），也可以自定义 #删除本地与远程仓库的连接 git remote remove origin #origin是远程仓库在本地的别名 参考链接 https://krislinzhao.github.io/docs/create-a-wesite-using-github-pages-and-hugo/\n","date":"2024-11-07T15:00:00+08:00","permalink":"https://0Hzc.github.io/p/%E4%BD%BF%E7%94%A8github-hugo%E9%83%A8%E7%BD%B2%E5%8D%9A%E5%AE%A2/","title":"使用github+hugo部署博客"},{"content":"this article is to record how to use hugo to build blog\nintroduction this server is running on github\u0026rsquo;s codespace . I\u0026rsquo;ll try to solve this problem that can\u0026rsquo;t open the website by access 0Hzc.github.io\n1.step1 get ready for the environment,to deploy this server need go , git ,and install hugo_extrended . Notice that hugo edition is hugo_extrended not the standard hugo : if use the standard hugo,you will can\u0026rsquo;t deploy other themes.\n2. step2 according to the docs from hugo\u0026rsquo;s official websites,use the following command:\n1 2 3 4 5 hugo new site quickstart //dirname is the directory for storing the project cd quickstart git submodule add https://xxxxxxx.git themes/xxx. //xxxxxxx is the url for the themes which you choose,xxx is the name of themes echo \u0026#34;theme = \u0026#39;xxx\u0026#39;\u0026#34; \u0026gt;\u0026gt; hugo.toml. // this command is add \u0026#34;theme = \u0026#39;xxx\u0026#39;\u0026#34; into the hugo.toml hugo server ","date":"2024-11-05T15:00:00+08:00","permalink":"https://0Hzc.github.io/p/how-to-deploy-blog-system-by-hugo/","title":"How to deploy blog system by hugo"}]